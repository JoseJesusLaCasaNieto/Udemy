{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch 2 Quick Intro\n",
        "\n",
        "* Reference notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/video_notebooks/pytorch_2_intro_video.ipynb\n",
        "* Book reference chapter - https://www.learnpytorch.io/pytorch_2_intro/\n",
        "* PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/\n"
      ],
      "metadata": {
        "id": "VOCs2pnyrljy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qE3dLqCst3_",
        "outputId": "bba9a8a0-0f86-4ffc-a7a6-14758234c4be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick code examples"
      ],
      "metadata": {
        "id": "NEjH0O3ksxGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before PyTorch 2.0"
      ],
      "metadata": {
        "id": "_zORWgGEtB7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet50()"
      ],
      "metadata": {
        "id": "qgnMoSbst56O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After PyTorch 2.0"
      ],
      "metadata": {
        "id": "u9rauXWRt-tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Some PyTorch 2.0 features may hinder the deployment of models - https://pytorch.org/get-started/pytorch-2.0/#inference-and-export"
      ],
      "metadata": {
        "id": "at5wve_oub0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet50() # Note: This could any model\n",
        "compiled_model = torch.compile(model)"
      ],
      "metadata": {
        "id": "if58RVjMuBdH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Getting setup"
      ],
      "metadata": {
        "id": "ZFXsw1aYuKYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check PyTorch version\n",
        "pt_version = torch.__version__\n",
        "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "\n",
        "# Install PyTorch 2.0 if necessary\n",
        "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1\n",
        "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\\\n",
        "          Though as of April 2023, Google Colab comes with PyTorch 2.0 pre-installed.\")\n",
        "    import torch\n",
        "    pt_version = torch.__version__\n",
        "    print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "else:\n",
        "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn8U7ViyvAJc",
        "outputId": "ca0269cd-2153-489e-8195-5e5adaba0162"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Current PyTorch version: 2.5.1+cu121 (should be 2.x+)\n",
            "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get GPU info\n",
        "\n",
        "Why get GPU info?\n",
        "\n",
        "Because PyTorch 2.0 features (torch.compile()) work best on newer NVIDIA GPUs.\n",
        "\n",
        "Well, what's a newer NVIDIA GPU?\n",
        "\n",
        "To find out if your GPU is compatible, see NVIDIA GPU compatibility scores - https://developer.nvidia.com/cuda-gpus\n",
        "\n",
        "If your GPU has a score of 8.0+, it can leverage *most* if not *all* of the new PyTorch 2.0 features.\n",
        "\n",
        "GPUs under 8.0 can still leverage PyTorch 2.0, however, the improvements may not be as noticable as those with 8.0+.\n",
        "\n",
        "**Note:** If you're wondering what GPU you should use for Deep Learning, check out Tim Dettmers blog post \"Which GPU for Deep Learning?\" - https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/"
      ],
      "metadata": {
        "id": "W-Iw3op6vRew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we're using a NVIDIA GPU\n",
        "if torch.cuda.is_available():\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
        "\n",
        "  # Get GPU name\n",
        "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
        "  gpu_name = gpu_name[1]\n",
        "  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n",
        "  print(f'GPU name: {GPU_NAME}')\n",
        "\n",
        "  # Get GPU capability score\n",
        "  GPU_SCORE = torch.cuda.get_device_capability()\n",
        "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
        "  if GPU_SCORE >= (8, 0):\n",
        "    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n",
        "  else:\n",
        "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
        "\n",
        "  # Print GPU info\n",
        "  print(f\"GPU information:\\n{gpu_info}\")\n",
        "\n",
        "else:\n",
        "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtEo-Dz-vc_S",
        "outputId": "e053975e-78d4-433a-b0cd-94e2f9c40839"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Globally set devices\n",
        "\n",
        "Previously, we've set the device of our tensors/models using `.to(device)`.\n",
        "\n",
        "* `tensor.to(device)`\n",
        "* `model.to(device)`\n",
        "\n",
        "But in PyTorch 2.0, it's possible to set the device with a context manager as well as a global device - https://pytorch.org/blog/pytorch-2.0-release/#beta-torchset_default_device-and-torchdevice-as-context-manager\n",
        "\n",
        "See the docs - https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html"
      ],
      "metadata": {
        "id": "W4-uZoBZxEI8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikYiwGc7yoWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}